{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable feature selection (DFS) demo\n",
    "\n",
    "Performs feature subset selection on a dataset and then evaluates those features with a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import yaml\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# the following helper class is adapted from \n",
    "# https://stackoverflow.com/questions/4417546/constantly-print-subprocess-output-while-process-is-running\n",
    "class Runner():\n",
    "    \n",
    "    def __init__(self, cmd, print=True):\n",
    "        self.cmd = cmd\n",
    "        self.print = print\n",
    "        self.stdout = ''\n",
    "        if self.print:\n",
    "            stderr = subprocess.STDOUT\n",
    "        else:\n",
    "            stderr = subprocess.PIPE\n",
    "            self.stderr = ''\n",
    "        self.proc = subprocess.Popen(self.cmd.split(), stdout=subprocess.PIPE,\n",
    "                                     stderr=stderr, universal_newlines=True)\n",
    "        self.returncode = None\n",
    "        \n",
    "    def __call__(self):\n",
    "        for stdout_line in iter(self.proc.stdout.readline, ''):\n",
    "            yield stdout_line \n",
    "        self.proc.stdout.close()\n",
    "        self.returncode = self.proc.wait()\n",
    "        \n",
    "    def run(self):\n",
    "        if self.print:\n",
    "            for l in self():\n",
    "                if self.print:\n",
    "                    print(l, end='')\n",
    "                self.stdout += l\n",
    "        else:\n",
    "            self.stdout,self.stderr = self.proc.communicate()\n",
    "            self.returncode = self.proc.returncode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform subset selection w/ DFS on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n",
      "Data loaded.\n",
      "Loaded mappings from /home/rishet/dfs_data/rcv1.mappings.\n",
      "Finding data statistics...\n",
      "/home/rishet/anaconda3/envs/dfs/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Centering: Read 1000 rows\n",
      "Centering: Read 2000 rows\n",
      "Centering: Read 3000 rows\n",
      "Centering: Read 4000 rows\n",
      "Centering: Read 5000 rows\n",
      "Centering: Read 6000 rows\n",
      "Centering: Read 7000 rows\n",
      "Centering: Read 8000 rows\n",
      "Centering: Read 9000 rows\n",
      "Centering: Read 10000 rows\n",
      "Scaling: Read 1000 rows\n",
      "Scaling: Read 2000 rows\n",
      "Scaling: Read 3000 rows\n",
      "Scaling: Read 4000 rows\n",
      "Scaling: Read 5000 rows\n",
      "Scaling: Read 6000 rows\n",
      "Scaling: Read 7000 rows\n",
      "Scaling: Read 8000 rows\n",
      "Scaling: Read 9000 rows\n",
      "Scaling: Read 10000 rows\n",
      "Spectral norm: Read 1000 rows\n",
      "Spectral norm: Read 2000 rows\n",
      "Spectral norm: Read 3000 rows\n",
      "Spectral norm: Read 4000 rows\n",
      "Spectral norm: Read 5000 rows\n",
      "Spectral norm: Read 6000 rows\n",
      "Spectral norm: Read 7000 rows\n",
      "Spectral norm: Read 8000 rows\n",
      "Spectral norm: Read 9000 rows\n",
      "Spectral norm: Read 10000 rows\n",
      "0 51.75521290676776 176.7342184256883\n",
      "Spectral norm: Read 1000 rows\n",
      "Spectral norm: Read 2000 rows\n",
      "Spectral norm: Read 3000 rows\n",
      "Spectral norm: Read 4000 rows\n",
      "Spectral norm: Read 5000 rows\n",
      "Spectral norm: Read 6000 rows\n",
      "Spectral norm: Read 7000 rows\n",
      "Spectral norm: Read 8000 rows\n",
      "Spectral norm: Read 9000 rows\n",
      "Spectral norm: Read 10000 rows\n",
      "1 0.689813072332789 5.995219070982691\n",
      "Spectral norm: Read 1000 rows\n",
      "Spectral norm: Read 2000 rows\n",
      "Spectral norm: Read 3000 rows\n",
      "Spectral norm: Read 4000 rows\n",
      "Spectral norm: Read 5000 rows\n",
      "Spectral norm: Read 6000 rows\n",
      "Spectral norm: Read 7000 rows\n",
      "Spectral norm: Read 8000 rows\n",
      "Spectral norm: Read 9000 rows\n",
      "Spectral norm: Read 10000 rows\n",
      "2 0.9316370881072573 10.235655763936501\n",
      "Spectral norm: Read 1000 rows\n",
      "Spectral norm: Read 2000 rows\n",
      "Spectral norm: Read 3000 rows\n",
      "Spectral norm: Read 4000 rows\n",
      "Spectral norm: Read 5000 rows\n",
      "Spectral norm: Read 6000 rows\n",
      "Spectral norm: Read 7000 rows\n",
      "Spectral norm: Read 8000 rows\n",
      "Spectral norm: Read 9000 rows\n",
      "Spectral norm: Read 10000 rows\n",
      "3 0.9830469875753473 11.363919110320456\n",
      "Spectral norm: Read 1000 rows\n",
      "Spectral norm: Read 2000 rows\n",
      "Spectral norm: Read 3000 rows\n",
      "Spectral norm: Read 4000 rows\n",
      "Spectral norm: Read 5000 rows\n",
      "Spectral norm: Read 6000 rows\n",
      "Spectral norm: Read 7000 rows\n",
      "Spectral norm: Read 8000 rows\n",
      "Spectral norm: Read 9000 rows\n",
      "Spectral norm: Read 10000 rows\n",
      "4 0.9951151697850458 11.664391004599308\n",
      "Spectral norm: Read 1000 rows\n",
      "Spectral norm: Read 2000 rows\n",
      "Spectral norm: Read 3000 rows\n",
      "Spectral norm: Read 4000 rows\n",
      "Spectral norm: Read 5000 rows\n",
      "Spectral norm: Read 6000 rows\n",
      "Spectral norm: Read 7000 rows\n",
      "Spectral norm: Read 8000 rows\n",
      "Spectral norm: Read 9000 rows\n",
      "Spectral norm: Read 10000 rows\n",
      "5 0.9984016209196027 11.753974284395902\n",
      "Spectral norm: Read 1000 rows\n",
      "Spectral norm: Read 2000 rows\n",
      "Spectral norm: Read 3000 rows\n",
      "Spectral norm: Read 4000 rows\n",
      "Spectral norm: Read 5000 rows\n",
      "Spectral norm: Read 6000 rows\n",
      "Spectral norm: Read 7000 rows\n",
      "Spectral norm: Read 8000 rows\n",
      "Spectral norm: Read 9000 rows\n",
      "Spectral norm: Read 10000 rows\n",
      "6 0.9994095750002522 11.784077332696008\n",
      "Spectral norm: Read 1000 rows\n",
      "Spectral norm: Read 2000 rows\n",
      "Spectral norm: Read 3000 rows\n",
      "Spectral norm: Read 4000 rows\n",
      "Spectral norm: Read 5000 rows\n",
      "Spectral norm: Read 6000 rows\n",
      "Spectral norm: Read 7000 rows\n",
      "Spectral norm: Read 8000 rows\n",
      "Spectral norm: Read 9000 rows\n",
      "Spectral norm: Read 10000 rows\n",
      "7 0.9997573167065503 11.795448336601588\n",
      "Spectral norm: Read 1000 rows\n",
      "Spectral norm: Read 2000 rows\n",
      "Spectral norm: Read 3000 rows\n",
      "Spectral norm: Read 4000 rows\n",
      "Spectral norm: Read 5000 rows\n",
      "Spectral norm: Read 6000 rows\n",
      "Spectral norm: Read 7000 rows\n",
      "Spectral norm: Read 8000 rows\n",
      "Spectral norm: Read 9000 rows\n",
      "Spectral norm: Read 10000 rows\n",
      "8 0.9998901334974489 11.800216012331502\n",
      "Spectral norm: Read 1000 rows\n",
      "Spectral norm: Read 2000 rows\n",
      "Spectral norm: Read 3000 rows\n",
      "Spectral norm: Read 4000 rows\n",
      "Spectral norm: Read 5000 rows\n",
      "Spectral norm: Read 6000 rows\n",
      "Spectral norm: Read 7000 rows\n",
      "Spectral norm: Read 8000 rows\n",
      "Spectral norm: Read 9000 rows\n",
      "Spectral norm: Read 10000 rows\n",
      "9 0.9999454902907923 11.802415789771125\n",
      "Dumped data statistics to /home/rishet/dfs_data/rcv1_seed0.datastats.\n",
      "[     1/  0/2.852 s] 0.497\n",
      "[     2/  0/0.198 s] 0.452\n",
      "[     3/  0/0.200 s] 0.406\n",
      "[     4/  0/0.197 s] 0.362\n",
      "[     5/  0/0.249 s] 0.320\n",
      "[     6/  0/0.207 s] 0.282\n",
      "[     7/  0/0.251 s] 0.248\n",
      "[     8/  0/0.264 s] 0.216\n",
      "[     9/  0/0.199 s] 0.188\n",
      "[    10/  0/0.211 s] 0.165\n",
      "[    11/  0/0.251 s] 0.145\n",
      "[    12/  0/0.200 s] 0.127\n",
      "[    13/  0/0.225 s] 0.112\n",
      "[    14/  0/0.246 s] 0.099\n",
      "[    15/  0/0.307 s] 0.089\n",
      "[    16/  0/0.196 s] 0.080\n",
      "[    17/  0/0.197 s] 0.073\n",
      "[    18/  0/0.200 s] 0.066\n",
      "[    19/  0/0.199 s] 0.062\n",
      "[    20/  0/0.200 s] 0.057\n",
      "tensor([ 8609,  9106, 19451, 21186, 24432, 26805, 28638, 29304, 30125, 31104,\n",
      "        33191, 33730, 36281, 37664, 37979, 41147, 42362, 46574],\n",
      "       device='cuda:0')\n",
      "18 features selected at penalty value 20\n",
      "Selected features saved to rcv1.dfs.4.20.features.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "usage: dfs.py [-h] [--dataset_config PATH] [--dn_data DIR] [--device DEVICE]\n",
    "              [--order ORDER] [--penalty PENALTY] [--lr LR] [--epochs EPOCHS]\n",
    "              [--workers WORKERS] [--seed SEED] [--batch BATCH]\n",
    "              [--path_output PATH]\n",
    "              dataset\n",
    "              \n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  --dataset_config PATH\n",
    "                        yml file holding values for fn_train, fn_eval, ncols,\n",
    "                        nrows, nrows_test, zero_based, neg_label, binary\n",
    "                        (default: ./datasets.yml)\n",
    "  --dn_data DIR         location of train/test files; mappings/datastats files\n",
    "                        stored here (default: .)\n",
    "  --device DEVICE       (default: 'cuda' if available, else 'cpu')\n",
    "  --order ORDER         {1..12} (default: 4)\n",
    "  --penalty PENALTY     (0,infty) (default: 10)\n",
    "  --lr LR               Adam learning rate (default: 0.1)\n",
    "  --epochs EPOCHS       (default: 1.0)\n",
    "  --workers WORKERS     for the pytorch dataloader (default: 4)\n",
    "  --seed SEED           pytorch seed (default: 0)\n",
    "  --batch BATCH         target batchsize (default: 1000)\n",
    "  --path_output PATH    output text file with selected features (default:\n",
    "                        ./dfs.features.NUM_SELECTED_FEATURES.txt)\n",
    "\"\"\"\n",
    "\n",
    "# the urls for the train/test files are provided in the README\n",
    "dataset = 'rcv1'\n",
    "dn_data = os.path.expanduser('~/dfs_data')\n",
    "\n",
    "order = 4\n",
    "w_penalty = 2e1\n",
    "path_output = '%s.dfs.%d.%g.features.txt' % (dataset,order,w_penalty)\n",
    "\n",
    "cmd = ('python dfs.py %s --dn_data %s --penalty %g --path_output %s'%(dataset,dn_data,w_penalty,path_output))\n",
    "\n",
    "\"\"\"\n",
    "for the first run on a dataset, DFS:\n",
    "    locates newlines for the train file,\n",
    "    estimates means/standard deviations,\n",
    "    estimates spectral norm iteratively (10 iters).\n",
    "the estimates are based on the first 10000 examples/labels.\n",
    "the newline mappings and dataset statistics are then saved (in dn_data) and loaded for subsequent runs.\n",
    "\"\"\"\n",
    "\n",
    "runner = Runner(cmd)\n",
    "runner.run()\n",
    "assert not runner.returncode, 'Failed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a linear model on train with selected features using MISSION's SGD. Then, predict on test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: mission_logistic_eval in MISSION/src/ needs to be compiled first\n",
    "\n",
    "mission_eval_exec = 'MISSION/src/mission_logistic_eval'\n",
    "datasets = yaml.safe_load(open('datasets.yml','rt'))\n",
    "\n",
    "cmd = ('%s %s %s %s %d'%(mission_eval_exec,\n",
    "                         os.path.join(dn_data,datasets[dataset]['fn_train']),\n",
    "                         os.path.join(dn_data,datasets[dataset]['fn_eval']),\n",
    "                         path_output, datasets[dataset]['neg_label']))\n",
    "\n",
    "runner = Runner(cmd, print=False)\n",
    "runner.run()\n",
    "assert not runner.returncode, 'Failed: %s'%runner.stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS AUC on test: 0.858275\n"
     ]
    }
   ],
   "source": [
    "Y = [[float(z) for z in x.split(' ')] for x in runner.stdout.splitlines()]\n",
    "print('DFS AUC on test: %g'%roc_auc_score([y[0] for y in Y],[y[1] for y in Y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare w/ MISSION feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: mission_logistic in MISSION/src/ needs to be compiled first\n",
    "\n",
    "mission_exec = 'MISSION/src/mission_logistic'\n",
    "\n",
    "n_feats = len(open(path_output,'rt').read().strip().splitlines())\n",
    "\n",
    "cmd = ('%s %s %s %s %d'%(mission_exec,\n",
    "                         os.path.join(dn_data,datasets[dataset]['fn_train']),\n",
    "                         os.path.join(dn_data,datasets[dataset]['fn_eval']),\n",
    "                         n_feats, datasets[dataset]['neg_label']))\n",
    "\n",
    "runner = Runner(cmd, print=False)\n",
    "runner.run()\n",
    "assert not runner.returncode, 'Failed: %s'%runner.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSION AUC on test: 0.623531\n"
     ]
    }
   ],
   "source": [
    "Y = [[float(z) for z in x.split(' ')] for x in runner.stdout.splitlines()]\n",
    "print('MISSION AUC on test: %g'%roc_auc_score([y[0] for y in Y],[y[1] for y in Y]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfs",
   "language": "python",
   "name": "dfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
